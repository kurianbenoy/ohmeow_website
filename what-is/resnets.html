<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>What are ResNets &amp; Why use it for computer vision tasks | ohmeow</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="What are ResNets &amp; Why use it for computer vision tasks" />
<meta name="author" content="Wayde Gilliam" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Insights from “Deep Learning for Coders with fastai &amp; PyTorch” and from around the world" />
<meta property="og:description" content="Insights from “Deep Learning for Coders with fastai &amp; PyTorch” and from around the world" />
<link rel="canonical" href="https://ohmeow.com/what-is/resnets" />
<meta property="og:url" content="https://ohmeow.com/what-is/resnets" />
<meta property="og:site_name" content="ohmeow" />
<meta property="og:image" content="https://ohmeow.com/images/articles/resnet.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-09T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://ohmeow.com/what-is/resnets","@type":"BlogPosting","headline":"What are ResNets &amp; Why use it for computer vision tasks","dateModified":"2021-11-09T00:00:00-06:00","datePublished":"2021-11-09T00:00:00-06:00","image":"https://ohmeow.com/images/articles/resnet.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://ohmeow.com/what-is/resnets"},"author":{"@type":"Person","name":"Wayde Gilliam"},"description":"Insights from “Deep Learning for Coders with fastai &amp; PyTorch” and from around the world","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ohmeow.com/feed.xml" title="ohmeow" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163296836-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-163296836-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/"><img style="height: 60px;" src="/images/ohmeow_logo.png" alt="ohmeow.com"></a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
  
          <div class="trigger"><a class="page-link" href="/about/"><span class="top-menu-text">About Me</span></a><a class="page-link" href="/guides/"><span class="top-menu-text">Guides</span></a><a class="page-link" href="/search/"><span class="top-menu-text">Search</span></a><a class="page-link" href="/categories/"><span class="top-menu-text">Tags</span></a></div>
        </nav></div>
  </header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">What are ResNets &amp; Why use it for computer vision tasks</h1><p class="page-description">Insights from <a href='https://github.com/fastai/fastbook'>"Deep Learning for Coders with fastai & PyTorch"</a> and from around the world</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-09T00:00:00-06:00" itemprop="datePublished">
        Nov 9, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Wayde Gilliam</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#fastai">fastai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#fastbook">fastbook</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#fastbook-chapter-1">fastbook-chapter-1</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#what-is">what-is</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#computer vision">computer vision</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#resnet">resnet</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/ohmeow/ohmeow_website/tree/master/_notebooks/2021-11-09-what-are-resnets.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/_notebooks/2021-11-09-what-are-resnets.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#What-is-a-ResNet-&-Why-use-it-for-computer-vision-tasks?">What is a ResNet &amp; Why use it for computer vision tasks? </a>
<ul>
<li class="toc-entry toc-h3"><a href="#What-other-things-can-use-images-recognizers-for-besides-image-tasks?">What other things can use images recognizers for besides image tasks? </a></li>
<li class="toc-entry toc-h3"><a href="#How-does-it-fare-against-more-recent-architectures-like-vision-transformers?">How does it fare against more recent architectures like vision transformers? </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#ResNet-best-practices">ResNet best practices </a></li>
<li class="toc-entry toc-h2"><a href="#An-example-using-the-high-level-API">An example using the high-level API </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Step-1:-Build-our-DataLoaders">Step 1: Build our DataLoaders </a></li>
<li class="toc-entry toc-h3"><a href="#Step-2:-Build-our-cnn_learner">Step 2: Build our cnn_learner </a></li>
<li class="toc-entry toc-h3"><a href="#Step-3:-Train">Step 3: Train </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-11-09-what-are-resnets.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Arguably the best architecture for most computer vision tasks, here we take a look at <strong>ResNet</strong> and how it can be used in fastai for a variety of such tasks.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="What-is-a-ResNet-&amp;-Why-use-it-for-computer-vision-tasks?">
<a class="anchor" href="#What-is-a-ResNet-&amp;-Why-use-it-for-computer-vision-tasks?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is a ResNet &amp; Why use it for computer vision tasks?<a class="anchor-link" href="#What-is-a-ResNet-&amp;-Why-use-it-for-computer-vision-tasks?"> </a>
</h2>
<p>A <strong>ResNet</strong> is a model architecture that has proven to work well in CV tasks. Several variants exist with different numbers of layers with the larger architectures taking longer to train and more prone to overfitting especially with smaller datasets.</p>
<p>The number represents the number of layers in this particular ResNet variant ... "(other options are 18, 50, 101, and 152) ... model architectures with more layers take longer to train and are more prone to overfitting ... on the other hand, when using more data, they can be qite a bit more accurate." <sup id="fnref-2" class="footnote-ref"><a href="#fn-2">2</a></sup></p>
<h3 id="What-other-things-can-use-images-recognizers-for-besides-image-tasks?">
<a class="anchor" href="#What-other-things-can-use-images-recognizers-for-besides-image-tasks?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What other things can use images recognizers for besides image tasks?<a class="anchor-link" href="#What-other-things-can-use-images-recognizers-for-besides-image-tasks?"> </a>
</h3>
<p>Sound, time series, malware classification ... "a good rule of thumb for converting a dataset into an image representation: if the human eye can recognize categories from the images, then a deep learning model should be able to do so too." <sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup></p>
<h3 id="How-does-it-fare-against-more-recent-architectures-like-vision-transformers?">
<a class="anchor" href="#How-does-it-fare-against-more-recent-architectures-like-vision-transformers?" aria-hidden="true"><span class="octicon octicon-link"></span></a>How does it fare against more recent architectures like vision transformers?<a class="anchor-link" href="#How-does-it-fare-against-more-recent-architectures-like-vision-transformers?"> </a>
</h3>
<p>Pretty well apparently (at least at the time this post was written) ...

</p>
<center>
    <div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">I'm pleased to announce that the 'ResNet strikes back' paper is now on arxiv! Moving the baseline forward to 80.4% top-1 for a vanilla ResNet-50 arch w/ better training recipes. No extra data, no distillation. <a href="https://t.co/WP3UDXfV0r">https://t.co/WP3UDXfV0r</a></p>— Ross Wightman (@wightmanr) <a href="https://twitter.com/wightmanr/status/1444852719773122565?ref_src=twsrc%5Etfw">October 4, 2021</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</center>


</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="ResNet-best-practices">
<a class="anchor" href="#ResNet-best-practices" aria-hidden="true"><span class="octicon octicon-link"></span></a>ResNet best practices<a class="anchor-link" href="#ResNet-best-practices"> </a>
</h2>
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Start with a smaller ResNet (like 18 or 34) and move up as needed.
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>If you have a lot of data, the bigger resnets will likely give you better results.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="An-example-using-the-high-level-API">
<a class="anchor" href="#An-example-using-the-high-level-API" aria-hidden="true"><span class="octicon octicon-link"></span></a>An example using the high-level API<a class="anchor-link" href="#An-example-using-the-high-level-API"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1:-Build-our-DataLoaders">
<a class="anchor" href="#Step-1:-Build-our-DataLoaders" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 1: Build our DataLoaders<a class="anchor-link" href="#Step-1:-Build-our-DataLoaders"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">PETS</span><span class="p">)</span><span class="o">/</span><span class="s1">'images'</span>

<span class="k">def</span> <span class="nf">is_cat</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders</span><span class="o">.</span><span class="n">from_name_func</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">label_func</span><span class="o">=</span><span class="n">is_cat</span><span class="p">,</span> <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why do we make images 224x224 pixels?</strong></p>
<p>"This is the standard size for historical reasons (old pretrained models require this size exactly) ... If you increase the size, you'll often get a model with better results since it will be able to focus on more details." <sup id="fnref-3" class="footnote-ref"><a href="#fn-3">3</a></sup>
</p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Train on progressively larger image sizes using the weights trained on smaller sizes as a kind of pretrained model.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Build-our-cnn_learner">
<a class="anchor" href="#Step-2:-Build-our-cnn_learner" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 2: Build our <code>cnn_learner</code><a class="anchor-link" href="#Step-2:-Build-our-cnn_learner"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see above, the architecture being used is a resnet with 18 layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-3:-Train">
<a class="anchor" href="#Step-3:-Train" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 3: Train<a class="anchor-link" href="#Step-3:-Train"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.161614</td>
      <td>0.040670</td>
      <td>0.013532</td>
      <td>01:03</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.062475</td>
      <td>0.020072</td>
      <td>0.006766</td>
      <td>01:04</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For more information on how transfer learning works, and the <code>fine_tune</code> method in particuarl, see this section in my <a href="https://ohmeow.com/what-is/machine-learning#Transfer-learning">"What is machine learning" post</a>.</p>
<p>For more metrics like <code>error_rate</code>, see my <a href="https://ohmeow.com/what-is/a-metric">"What is a metric" post</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p></p>
<div class="footnotes"><p id="fn-2">2. "Chaper 1: Your Deep Learning Journey". In <em><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">The Fastbook</a></em> pp.30-31.<a href="#fnref-2" class="footnote footnotes">↩</a></p></div>
<p></p>
<div class="footnotes"><p id="fn-1">1. Ibid., p.39. Pages 36-39 provides several examples of how non-image data can be converted to an image for such a purpose.<a href="#fnref-1" class="footnote footnotes">↩</a></p></div>
<p></p>
<div class="footnotes"><p id="fn-3">3. Ibid., p.28<a href="#fnref-3" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
</div>

<script type="application/vnd.jupyter.widget-state+json">
{"55007a0aa5074700be062c2347e64fb3": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_eac7de645cb24820a264714b152a3add", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_f8e8797b82b24e9797957a2b92d8056a", "IPY_MODEL_2086a8ad3a834a87ae0de85f979848fc", "IPY_MODEL_d3992b1f8b2b4934a58d123ef9dc1610"]}}, "eac7de645cb24820a264714b152a3add": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "f8e8797b82b24e9797957a2b92d8056a": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_view_name": "HTMLView", "style": "IPY_MODEL_d5d61524d8884dfa922467ab506579de", "_dom_classes": [], "description": "", "_model_name": "HTMLModel", "placeholder": "\u200b", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": "100%", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_dc803f68c4194b63a46718daac142d29"}}, "2086a8ad3a834a87ae0de85f979848fc": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_view_name": "ProgressView", "style": "IPY_MODEL_9bdb240d8a714c7dbc394dcecb01ded2", "_dom_classes": [], "description": "", "_model_name": "FloatProgressModel", "bar_style": "success", "max": 46830571, "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": 46830571, "_view_count": null, "_view_module_version": "1.5.0", "orientation": "horizontal", "min": 0, "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_7c4cb3e1519d4de4a63e78119ceeede0"}}, "d3992b1f8b2b4934a58d123ef9dc1610": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_view_name": "HTMLView", "style": "IPY_MODEL_15a5bd961fff498fa8516de9fdcc0ca7", "_dom_classes": [], "description": "", "_model_name": "HTMLModel", "placeholder": "\u200b", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": " 44.7M/44.7M [00:00&lt;00:00, 97.4MB/s]", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_605d70a5cef44be9a1944ab5a26a5051"}}, "d5d61524d8884dfa922467ab506579de": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}}, "dc803f68c4194b63a46718daac142d29": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "9bdb240d8a714c7dbc394dcecb01ded2": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_view_name": "StyleView", "_model_name": "ProgressStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "bar_color": null, "_model_module": "@jupyter-widgets/controls"}}, "7c4cb3e1519d4de4a63e78119ceeede0": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}, "15a5bd961fff498fa8516de9fdcc0ca7": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}}, "605d70a5cef44be9a1944ab5a26a5051": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "overflow": null, "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "width": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "overflow_y": null, "overflow_x": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "grid_row": null, "max_height": null, "align_content": null, "visibility": null, "align_self": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "max_width": null, "order": null, "_view_module_version": "1.2.0", "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "display": null, "left": null}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ohmeow/ohmeow_website"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/what-is/resnets" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p>A full-stack web application and ML development company.</p>
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a class="fa-icon" rel="me" href="mailto:wgilliam@ohmeow.com" title="wgilliam@ohmeow.com"><i class="far fa-envelope"></i></a></li><li><a rel="me" href="https://github.com/ohmeow" title="ohmeow"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/waydegilliam" title="waydegilliam"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul></div>

  </div>

</footer>

<script>
  // method will ensure the floating header isn't covering the note header
  function goToNote(elId) {
    const el = document.getElementById(elId);
    const elPos = el.getBoundingClientRect().top + document.documentElement.scrollTop;
      
    window.focus();
    window.scrollTo(0, elPos - 90);
  }

  // ensure target note shows below floating header on # change
  window.addEventListener("hashchange", (ev) => { 
    const hash = ev.target.location.hash
    if (hash) {
      goToNote(hash.substring(1))
    }
  });

  // onload, ensure note shows below floating header
  window.addEventListener("load", (ev) => { 
    const hash = ev.target.location.hash
    if (hash) {
      goToNote(hash.substring(1))
    }
  });
</script></body>

</html>
