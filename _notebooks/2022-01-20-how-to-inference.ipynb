{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "how-to-use-the-datablock-api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBJ/qpZlaqLF/ot+2r8NNN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJL4-Qwluy4"
      },
      "source": [
        "# \"How to do inference\"\n",
        "> \"Insights from [\\\"Deep Learning for Coders with fastai & PyTorch\\\"](https://github.com/fastai/fastbook) and from around the world\"\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- hide_binder_badge: true\n",
        "- comments: true\n",
        "- author: Wayde Gilliam\n",
        "- categories: [fastai, fastbook, fastbook chapter 2, how to, data, inference]\n",
        "- image: images/articles/inference.png\n",
        "- hide: false\n",
        "- search_exclude: false\n",
        "- permalink: /how-to/inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLRXSFoNZrZo"
      },
      "source": [
        "#hide\n",
        "! pip install fastai -Uqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nilyL8K728RC"
      },
      "source": [
        "**Inference** is about how you used your trained model to get predictions on new data. It is often structured to perform in real-time on a single (or at least a small set of data) item or in the background where large quantities of data can be processed together in batches.  For the former, we can use fastai's `Learner.predict()` method while for the later we can use either fastai's `Learner.get_preds()` or write our own inference loop using PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### `export()` and `predict()`\n",
        "\n",
        "\"a model consists of two parts: the *architecture* and the trained *parameters*.\" {% fn 1 %} You can use it just like any other function\n",
        "\n",
        "\n",
        "```\n",
        "#saves the architecture, the trained parameters, and the definintion of how to create your DataLoaders\n",
        "learn.export() \n",
        "```\n",
        "\n",
        "> Note: fastai ... uses your validation set `DataLoader` for inference by default, ***so your data augmentation will not be applied.***\n",
        "\n",
        "\n",
        "```\n",
        "inf_learn = load_learner(path/'export.pkl')\n",
        "inf_learn.predict('images/grizzly.jpg')\n",
        "inf_learn.dls.vocab # => To view possible classification categories/labels\n",
        "```\n",
        "\n",
        "\n",
        "For options on how to deploy your app, see the [Deployment section](https://course.fast.ai/) in the course website. I personally like to use [FastAPI](https://fastapi.tiangolo.com/) and there is a good [starter template here](https://forums.fast.ai/t/fastai2-fastapi-starter-template/69373?u=wgpubs) for that."
      ],
      "metadata": {
        "id": "B5lKiEUMJGwG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKAQxMmyx8OB"
      },
      "source": [
        "---\n",
        "{{ '\"Chaper 2: From Model to Production\". In *[The Fastbook](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527)* p.78' | fndetail: 1 }}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtch8hC7uPk2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}