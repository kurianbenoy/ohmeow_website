{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-11-06-ajtfb-chapter-1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdNSL1PRd1KGn074fgR3oL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJL4-Qwluy4"
      },
      "source": [
        "# \"A Journey Through Fastbook (AJTFB) - Chapter 2\"\n",
        "> \"The second in a weekly-ish series where I revisit the fast.ai book, [\\\"Deep Learning for Coders with fastai & PyTorch\\\"](https://github.com/fastai/fastbook), and provide commentary on the bits that jumped out to me chapter by chapter.  So without further adieu, let's go!\"\n",
        "\n",
        "- toc: false\n",
        "- branch: master\n",
        "- badges: true\n",
        "- hide_binder_badge: true\n",
        "- comments: true\n",
        "- author: Wayde Gilliam\n",
        "- categories: [fastai, fastbook]\n",
        "- image: images/articles/fastbook.jpg\n",
        "- hide: false\n",
        "- search_exclude: false"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfcRNESotGLU"
      },
      "source": [
        "Other posts in this series:  \n",
        "[A Journey Through Fastbook (AJTFB) - Chapter 1](https://ohmeow.com/posts/2020/11/06/ajtfb-chapter-1.html)\n",
        "\n",
        "## Chapter 2\n",
        "\n",
        "---\n",
        "### Starting Your Project\n",
        "\n",
        "#### Things to think about when deciding on project feasibility\n",
        "\n",
        "> When selecting a project, the most important consideration is data availability\n",
        "\n",
        "If you don't have enough quality data ... good luck :)\n",
        "\n",
        "\n",
        "> Important: Consider that **data augmentation** can alleviate both the need for more manual labelling and also protect you from problems with *out-of-domain* data (e.g. when unexpected image types arise in the data when the model is being used in production) by synthetically creating more data likely to be seen that may not be in your dataset as is.\n",
        "\n",
        "\n",
        "> ... iterate from end to end in your project; don't spend months fine-tuning your model, or polishing the perfect GUI, or labeling the perfect dataset\n",
        "\n",
        "\n",
        "This is good advice for *any* software project ...***fail early and fail often***. If you don't, you're likely to only uncover critical problems much later than you would have before, and even worse, you're likely to not produce anything at all! In the world of deep learning there are a number of tools, that while helpful, can really get you so bogged down that you never deploy something usable (e.g., experiment tracking tools, hyperparameter optimization libraries, etc...). Also, remember that getting something in production is a different task from winning a kaggle competition, where the later may require use of some of those aforementioned tools and the ensembling of dozens of models. For production, something better than human is often good enough to get out there and through refactoring, improve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x904qZCHHcb"
      },
      "source": [
        "---\n",
        "## The Drivetrain Approach\n",
        "\n",
        "![](https://raw.githubusercontent.com/fastai/fastbook/41a60e44d588139a03452f1907359fc2322f8d5f/images/drivetrain-approach.png)\n",
        "\n",
        "### Four Steps\n",
        "\n",
        "#### Step 1: Define your objective(s)\n",
        "\n",
        "It's amazing how in my 20+ years as a developer, how rare it is that a customer is able to clearly define what they want! In my experience, more than not, it is the developers that end up defining the goals. Not having a clear objective is likely to waste time, energy, and money to produce something that won't even see the light of day.  You can't gauge the completion or quality of any software project without clear objective(s).\n",
        "\n",
        "Ex.1: Show most relevant search results.  \n",
        "Ex.2: Drive additional sales by recommending to customers items to purchase they otherwise wouldn't\n",
        "\n",
        "#### Step 2: What actions can you take to achieve those objective(s)?\n",
        "\n",
        "What things can make your goals a reality. Pretty simple.\n",
        "\n",
        "Ex.1: Ranking the search results will help show the most relevants ones first.  \n",
        "Ex.2: Ranking the recommendations will help.\n",
        "\n",
        "#### Step 3: What data is needed to take those actions?\n",
        "\n",
        "If you don't have the data, you'll need to get it ... because the data pulls the levers which get you closer to your objective(s).\n",
        "\n",
        "Ex.1: Seeing what how pages linked to other pages.  \n",
        "Ex.2: Collecting data on what customers purchased, what was recommended, and what they did with that info.\n",
        "\n",
        "#### Step 4: Build models\n",
        "\n",
        "Only once you have the data and know what actions you want to be able to take based on the information within it, do you being modeling ... first, defining what models you can even build with that data and second, what data you need to collect for models you can't.\n",
        "\n",
        "Ex.1: A model that takes the page relation data and predicts a ranking given a query.  \n",
        "Ex.2: Two models that predict the purchasing proabilities conditional on seeing or not seeing a recommendation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-miYMMSOC9J"
      },
      "source": [
        "! pip install fastai -q\n",
        "from fastai.vision import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2uxHGE5IK0a"
      },
      "source": [
        "---\n",
        "### Downloading images, getting the downloaded images, & removing those that are corrupt\n",
        "\n",
        "1. Use `download_images` listed as URLs in a text file `urls` to download the actual images locally.  \n",
        "2. Get the file path to the images via `get_image_files` in an `L` object.  \n",
        "3. Get rid of the corrupt images using `verify_images` and `Path.unlink`.\n",
        "\n",
        "```\n",
        "path = Path('bears/grizzly')\n",
        "download_images(path, urls=image_urls.txt)\n",
        "\n",
        "file_paths = get_image_files(path)\n",
        "failed = verify_images(file_paths)\n",
        "failed.map(Path.unlink)\n",
        "```\n",
        "\n",
        "Notice how `L`'s `map` method is used to apply the `Path.unlink` function to each item in-place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7ZF3BdAItCG"
      },
      "source": [
        "---\n",
        "### Getting help\n",
        "\n",
        "A few of ways ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snNoVRYDMJ6n"
      },
      "source": [
        "# method signature only\n",
        "download_images?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9NzSjdiMN_-"
      },
      "source": [
        "# full source of method\n",
        "download_images??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpNSL-B1MQtp"
      },
      "source": [
        "# get link to fastai docs\n",
        "doc(download_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5lNegHdMxEM"
      },
      "source": [
        "You can also use `pdb.set_trace` (in code) or  `%debug`(in a new cell following the one with the error) to step through your code.  I use the former all the time ... its a great way to debug and also learn what the code is doing and why.  For example, I use it to look at the shape of things as the travel through and out of different layers in my NNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W7daFGlMwNA"
      },
      "source": [
        "import pdb\n",
        "def div_by_zero():\n",
        "  pdb.set_trace()\n",
        "  x = 1/0\n",
        "  print('here')\n",
        "\n",
        "# uncomment this to see what I'm talking about ...\n",
        "# div_by_zero()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZoR3dj_Tu6C"
      },
      "source": [
        "---\n",
        "### DataBlock API Basics\n",
        "\n",
        "In order to make your data \"modelable\" (via `DataLoader`s, you need to tell fastai 4 things:\n",
        "1. What kind of data you are working with\n",
        "2. How to get the data\n",
        "3. How to label the data\n",
        "4. How to create a validation set\n",
        "\n",
        "Here's an example of how this is done with the `DataBlock API`:\n",
        "```\n",
        "d_block = DataBlock(\n",
        "  blocks=(ImageBlock, CategoryBlock),              #=> our independent and dependent variable datatypes\n",
        "  get_items=get_image_files,                       #=> how to get our data\n",
        "  splitter=RandomSplitter(valid_pct=0.2, seed=42), #=> how to create the validation set\n",
        "  get_y=parent_label,                              #=> how to label our data\n",
        "  item_tfms=Resize(128)                            #=> code that runs against each item as it is fetched\n",
        "```\n",
        "\n",
        "> Important: Use the `seed` argument to ensure you get the same training/validation set each time you run that code; else you won't be able to know if, as you change hyperparameter values, your model performance changed because of those values and/or because of difference in your training/validation sets!\n",
        "\n",
        "\n",
        "\n",
        "> ... a `DataBlock object` ... is like a template for creating a `DataLoaders` object\n",
        "\n",
        "\n",
        "For more detailed discussion of the DataBlock API, see the following resources:\n",
        "\n",
        "1. My article [\"Finding DataBlock Nirvana with fast.ai v2 - Part 1\"](https://ohmeow.com/posts/2020/04/11/finding-datablock-nirvana-part-1.html)\n",
        "\n",
        "2. The [\"Walk with fastai2\" videos](https://forums.fast.ai/t/a-walk-with-fastai2-vision-study-group-and-online-lectures-megathread/59929)\n",
        "\n",
        "3. The [fastai docs](https://docs.fast.ai/data.block) and the [DataBlock Tutorials](https://docs.fast.ai/tutorial.datablock)\n",
        "\n",
        "Once you've defined your blueprint for how to get your modelable data (i.e., your `DataLoaders`), you need to pass it the \"actual source\" of your data, which can be a path or a DataFrame or whatever.\n",
        "```\n",
        "dls = d_block.dataloaders(path)\n",
        "```\n",
        "\n",
        "Use `dls.show_batch(...)` or `dls.valid.show_batch(...)` to visualize your training/validation data.\n",
        "\n",
        "> Important: You can change the transforms in your DataBlock by reusing the existing DataBlock using `d_block.new`\n",
        "\n",
        "```\n",
        "d_block = d_block.new(item_tfms=Resize(128, ResizeMethod.squish))\n",
        "dls = d_block.dataloaders(path)\n",
        "...\n",
        "d_block = d_block.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeroes'))\n",
        "dls = d_block.dataloaders(path)\n",
        "...\n",
        "```\n",
        "\n",
        "> Important: For resizing ... \"what we normally do in practice is to randomly select part of the image and then crop to just that part. On each epoch ... we randomly select a different part of each image. This means that our model can learn to focus on, and recognize, different features in our images. It also reflects how images work in the real world: different photos of the same thing may be framed in slightly different ways.\"  This is done using the **RandomResizedCrop** transform.\n",
        "\n",
        "```\n",
        "d_block = d_block.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\n",
        "```\n",
        "\n",
        "`min_scale`: \"how much of the image to select at minimum each time.\" 0.5 = select 50% of the image at minimum.\n",
        "\n",
        "> Important: Pass `unique=True` to your `show_batch` functions \"to have the same image repeated with different versions\" of the transforms you've defined.\n",
        "\n",
        "\n",
        "\n",
        "**Data augmentation** transorms (e.g., rotation, flipping, perspective warping, brightness changes, contrast changes, etc...) are defined as **batch transforms** and run on the GPU.\n",
        "\n",
        "> Important: Item Transforms are applied to an item from your dataset when it is fetched, Batch Transforms are applied to a collection of items on the GPU *after* they have been collated into the same shape.\n",
        "\n",
        "```\n",
        "d_block = d_block.new(item_tfms=RandomResizedCrop(128, min_scale=0.3), batch_tfms=aug_transforms(mult=2))\n",
        "```\n",
        "\n",
        "`batch_tfms`: Your batch transforms, or more correctly your *after batch* transforms\n",
        "\n",
        "> Important: `aug_transforms` are \"a standard set of augmentations that we have found work pretty well\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35rQclh0duXV"
      },
      "source": [
        "---\n",
        "### Cleaning your model through training\n",
        "\n",
        "> Important: \"It's helpful to see where exactly our errors are occuring, to see whether they're due to a dataset problem ... or a model problem\" using `plot_top_losses`\n",
        "\n",
        "```\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_top_losses(5, nrows=1) #> show the 5 examples with the highest loss\n",
        "```\n",
        "\n",
        "> Important: A \"model can help you find data issues more quickly ... so we normally prefer to train a quick and simple model first, and then use it to help with data cleaning.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se2j5Is-fDMJ"
      },
      "source": [
        "---\n",
        "### Inference\n",
        "\n",
        "> \"a model consists of two parts: the *architecture* and the trained *parameters*.\"  You can use it just like any other function\n",
        "\n",
        "\n",
        "```\n",
        "#saves the architecture, the trained parameters, and the definintion of how to create your DataLoaders\n",
        "learn.export() \n",
        "```\n",
        "\n",
        "> fastai ... uses your validation set `DataLoader` for inference by default, so your data augmentation \n",
        "> will not be applied.\n",
        "\n",
        "\n",
        "```\n",
        "inf_learn = load_learner(path/'export.pkl')\n",
        "inf_learn.predict('images/grizzly.jpg')\n",
        "inf_learn.dls.vocab # => To view possible classification categories/labels\n",
        "```\n",
        "\n",
        "\n",
        "For options on how to deploy your app, see the [Deployment section](https://course.fast.ai/) in the course website. I personally like to use [FastAPI](https://fastapi.tiangolo.com/) and there is a good [starter template here](https://forums.fast.ai/t/fastai2-fastapi-starter-template/69373?u=wgpubs) for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgOOZ8A-g83q"
      },
      "source": [
        "---\n",
        "### How to Avoid Disaster\n",
        "\n",
        "> Important: Your model is only as good as the data it was trained on\n",
        "\n",
        "\n",
        "\n",
        "Two problems to watch out for:\n",
        "\n",
        "1. **out-of-domain data**: \"data that our model sees in production that is very different to wath it saw during training.\n",
        "2. **domain shift**: \"whereby the type of data that our model sees changes over time.\"\n",
        "\n",
        "Mitigation steps:\n",
        "\n",
        "![](https://github.com/fastai/fastbook/raw/41a60e44d588139a03452f1907359fc2322f8d5f/images/att_00061.png)\n",
        "\n",
        "> Where possible, the **first step** is to use an entirely manual process with your model running in \n",
        "> parallel and not being used to directly drive any actions.\n",
        "\n",
        "> The **second step** is to try and limit the scop of the model.\n",
        "\n",
        "> The **third step** is to gradually increase the scope of your rollout.\n",
        "\n",
        "\n",
        "> Important: \"Try to think about all the ways in which your system could go wrong, and then think about what measure or report or picture could reflect that problem, and ensure that your regular reporting includes that information.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSwEOzDpHHBj"
      },
      "source": [
        "---\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. https://book.fast.ai - The book's website; it's updated regularly with new content and recommendations from everything to GPUs to use, how to run things locally and on the cloud, etc...\n",
        "\n",
        "2. https://docs.fast.ai/ - The library's documentation; includes tutorials and other tips for development.\n",
        "\n",
        "3. https://forums.fast.ai/ - If you're not part of the community yet, you should be. Before posting a question, search to see if it has been answered already (95% of the time, it has).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2wEfmj5CLA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}