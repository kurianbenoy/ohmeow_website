{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMd7bimDP6XwOX6h4PE38pK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55007a0aa5074700be062c2347e64fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eac7de645cb24820a264714b152a3add",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8e8797b82b24e9797957a2b92d8056a",
              "IPY_MODEL_2086a8ad3a834a87ae0de85f979848fc",
              "IPY_MODEL_d3992b1f8b2b4934a58d123ef9dc1610"
            ]
          }
        },
        "eac7de645cb24820a264714b152a3add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8e8797b82b24e9797957a2b92d8056a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5d61524d8884dfa922467ab506579de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc803f68c4194b63a46718daac142d29"
          }
        },
        "2086a8ad3a834a87ae0de85f979848fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9bdb240d8a714c7dbc394dcecb01ded2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c4cb3e1519d4de4a63e78119ceeede0"
          }
        },
        "d3992b1f8b2b4934a58d123ef9dc1610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15a5bd961fff498fa8516de9fdcc0ca7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 97.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_605d70a5cef44be9a1944ab5a26a5051"
          }
        },
        "d5d61524d8884dfa922467ab506579de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc803f68c4194b63a46718daac142d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bdb240d8a714c7dbc394dcecb01ded2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c4cb3e1519d4de4a63e78119ceeede0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15a5bd961fff498fa8516de9fdcc0ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "605d70a5cef44be9a1944ab5a26a5051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJL4-Qwluy4"
      },
      "source": [
        "# \"What are ResNets & Why use it for computer vision tasks\"\n",
        "> \"Insights from [\\\"Deep Learning for Coders with fastai & PyTorch\\\"](https://github.com/fastai/fastbook) and from around the world\"\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- hide_binder_badge: true\n",
        "- comments: true\n",
        "- author: Wayde Gilliam\n",
        "- categories: [fastai, fastbook, fastbook chapter 1, what is, computer vision, resnet]\n",
        "- image: images/articles/resnet.png\n",
        "- hide: false\n",
        "- search_exclude: false\n",
        "- permalink: /what-is/resnets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLRXSFoNZrZo",
        "outputId": "9ac00b21-d318-4aca-f5fd-858f33df4f0d"
      },
      "source": [
        "#hide\n",
        "! pip install fastai -Uqq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nilyL8K728RC"
      },
      "source": [
        "Arguably the best architecture for most computer vision tasks, here we take a look at **ResNet** and how it can be used in fastai for a variety of such tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka023QwyrNF-"
      },
      "source": [
        "---\n",
        "## What is a ResNet & Why use it for computer vision tasks?\n",
        "\n",
        "A **ResNet** is a model architecture that has proven to work well in CV tasks. Several variants exist with different numbers of layers with the larger architectures taking longer to train and more prone to overfitting especially with smaller datasets.\n",
        "\n",
        "The number represents the number of layers in this particular ResNet variant ... \"(other options are 18, 50, 101, and 152) ... model architectures with more layers take longer to train and are more prone to overfitting ... on the other hand, when using more data, they can be qite a bit more accurate.\" {% fn 2 %}\n",
        "\n",
        "### What other things can use images recognizers for besides image tasks? \n",
        "\n",
        "Sound, time series, malware classification ... \"a good rule of thumb for converting a dataset into an image representation: if the human eye can recognize categories from the images, then a deep learning model should be able to do so too.\" {% fn 1 %}\n",
        "\n",
        "### How does it fare against more recent architectures like vision transformers?\n",
        "\n",
        "Pretty well apparently (at least at the time this post was written) ...\n",
        "\n",
        "> twitter: https://twitter.com/wightmanr/status/1444852719773122565\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKurr9j6Wc5q"
      },
      "source": [
        "---\n",
        "## ResNet best practices\n",
        "\n",
        "\n",
        "> Tip: Start with a smaller ResNet (like 18 or 34) and move up as needed.\n",
        "\n",
        "\n",
        "> Note: If you have a lot of data, the bigger resnets will likely give you better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk7NChijZdQl"
      },
      "source": [
        "---\n",
        "## An example using the high-level API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afjiX4Paaraq"
      },
      "source": [
        "### Step 1: Build our DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "gQh8yEyxZkCs",
        "outputId": "66a33c08-dd07-473e-f4a4-1315ecd58846"
      },
      "source": [
        "#hide_output\n",
        "from fastai.vision.all import *\n",
        "\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def is_cat(x): return x[0].isupper()\n",
        "\n",
        "dls = ImageDataLoaders.from_name_func(path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [811712512/811706944 00:14<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZA5Xer0ZTyE"
      },
      "source": [
        "**Why do we make images 224x224 pixels?**\n",
        "\n",
        "\"This is the standard size for historical reasons (old pretrained models require this size exactly) ... If you increase the size, you'll often get a model with better results since it will be able to focus on more details.\" {% fn 3 %}\n",
        "\n",
        "\n",
        "> Tip: Train on progressively larger image sizes using the weights trained on smaller sizes as a kind of pretrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-FE4J9Jay05"
      },
      "source": [
        "### Step 2: Build our `cnn_learner`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "55007a0aa5074700be062c2347e64fb3",
            "eac7de645cb24820a264714b152a3add",
            "f8e8797b82b24e9797957a2b92d8056a",
            "2086a8ad3a834a87ae0de85f979848fc",
            "d3992b1f8b2b4934a58d123ef9dc1610",
            "d5d61524d8884dfa922467ab506579de",
            "dc803f68c4194b63a46718daac142d29",
            "9bdb240d8a714c7dbc394dcecb01ded2",
            "7c4cb3e1519d4de4a63e78119ceeede0",
            "15a5bd961fff498fa8516de9fdcc0ca7",
            "605d70a5cef44be9a1944ab5a26a5051"
          ]
        },
        "id": "9gtucnKPa6jZ",
        "outputId": "9d6a05a3-51c3-46e9-e415-750837e00f5a"
      },
      "source": [
        "#hide_output\n",
        "learn = cnn_learner(dls, resnet18, metrics=error_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55007a0aa5074700be062c2347e64fb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHqXqzuRbdrJ"
      },
      "source": [
        "As you can see above, the architecture being used is a resnet with 18 layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uJ57b2Mbskm"
      },
      "source": [
        "### Step 3: Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "wVPZRMWQbu4m",
        "outputId": "7beac0d4-b011-4d0d-9cf5-60dc690f23c0"
      },
      "source": [
        "learn.fine_tune(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.161614</td>\n",
              "      <td>0.040670</td>\n",
              "      <td>0.013532</td>\n",
              "      <td>01:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.062475</td>\n",
              "      <td>0.020072</td>\n",
              "      <td>0.006766</td>\n",
              "      <td>01:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kmR11E6cViw"
      },
      "source": [
        "For more information on how transfer learning works, and the `fine_tune` method in particuarl, see this section in my [\"What is machine learning\" post](https://ohmeow.com/what-is/machine-learning#Transfer-learning).\n",
        "\n",
        "For more metrics like `error_rate`, see my [\"What is a metric\" post](https://ohmeow.com/what-is/a-metric)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKAQxMmyx8OB"
      },
      "source": [
        "---\n",
        "{{ '\"Chaper 1: Your Deep Learning Journey\". In *[The Fastbook](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527)* pp.30-31.' | fndetail: 2 }}\n",
        "\n",
        "{{ 'Ibid., p.39. Pages 36-39 provides several examples of how non-image data can be converted to an image for such a purpose.' | fndetail: 1 }}\n",
        "\n",
        "{{ 'Ibid., p.28' | fndetail: 3 }}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtch8hC7uPk2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}